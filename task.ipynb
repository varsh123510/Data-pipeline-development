{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c97620d5-4667-47c1-9a11-301538584f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "    Age   Salary         City Purchased\n",
      "0  25.0  50000.0     New York       Yes\n",
      "1  30.0  60000.0  Los Angeles        No\n",
      "2   NaN  55000.0     New York       Yes\n",
      "3  35.0      NaN      Chicago        No\n",
      "4  40.0  80000.0  Los Angeles       Yes\n",
      "\n",
      "Transformed Data:\n",
      "   Age    Salary  City_Chicago  City_Los Angeles  City_New York\n",
      "0 -1.5 -1.104482           0.0               0.0            1.0\n",
      "1 -0.5 -0.122720           0.0               1.0            0.0\n",
      "2  0.0 -0.613601           0.0               0.0            1.0\n",
      "3  0.5  0.000000           1.0               0.0            0.0\n",
      "4  1.5  1.840803           0.0               1.0            0.0\n",
      "\n",
      "Final DataFrame:\n",
      "   Age    Salary  City_Chicago  City_Los Angeles  City_New York Purchased\n",
      "0 -1.5 -1.104482           0.0               0.0            1.0       Yes\n",
      "1 -0.5 -0.122720           0.0               1.0            0.0        No\n",
      "2  0.0 -0.613601           0.0               0.0            1.0       Yes\n",
      "3  0.5  0.000000           1.0               0.0            0.0        No\n",
      "4  1.5  1.840803           0.0               1.0            0.0       Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Create a sample dataset\n",
    "data = {\n",
    "    \"Age\": [25, 30, np.nan, 35, 40],\n",
    "    \"Salary\": [50000, 60000, 55000, np.nan, 80000],\n",
    "    \"City\": [\"New York\", \"Los Angeles\", \"New York\", \"Chicago\", \"Los Angeles\"],\n",
    "    \"Purchased\": [\"Yes\", \"No\", \"Yes\", \"No\", \"Yes\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "# Step 2: Split into features and target\n",
    "X = df.drop(\"Purchased\", axis=1)\n",
    "y = df[\"Purchased\"]\n",
    "\n",
    "# Step 3: Define preprocessing steps\n",
    "numeric_features = [\"Age\", \"Salary\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = [\"City\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Combine preprocessors in a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 4: Create a full pipeline with preprocessing and loading\n",
    "pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor)])\n",
    "\n",
    "# Step 5: Fit and transform the data\n",
    "X_preprocessed = pipeline.fit_transform(X)\n",
    "\n",
    "# Convert the transformed data into a DataFrame\n",
    "# Extract feature names after one-hot encoding\n",
    "categorical_columns = list(pipeline.named_steps[\"preprocessor\"]\n",
    "                           .named_transformers_[\"cat\"]\n",
    "                           .named_steps[\"onehot\"]\n",
    "                           .get_feature_names_out(categorical_features))\n",
    "\n",
    "all_columns = numeric_features + categorical_columns\n",
    "X_transformed_df = pd.DataFrame(X_preprocessed, columns=all_columns)\n",
    "\n",
    "print(\"\\nTransformed Data:\")\n",
    "print(X_transformed_df)\n",
    "\n",
    "# Step 6: Combine transformed features with target\n",
    "final_df = pd.concat([X_transformed_df, y.reset_index(drop=True)], axis=1)\n",
    "print(\"\\nFinal DataFrame:\")\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f620bb-5ca1-4b67-a3a8-20ea3d03f7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
